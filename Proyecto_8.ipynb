{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "Los clientes de Beta Bank se están yendo, cada mes, poco a poco. Los banqueros descubrieron que es más barato salvar a los clientes existentes que atraer nuevos.\n",
    "\n",
    "Se necesita predecir si un cliente dejará el banco pronto. Se cuenta con los datos sobre el comportamiento pasado de los clientes y la terminación de contratos con el banco.\n",
    "\n",
    "Se creará un modelo con el máximo valor F1 posible (debe superar al menos 0.59)\n",
    "Además, se medirá la métrica AUC-ROC y se la comparará con el valor F1.\n",
    "  \n",
    " \n",
    " # Tabla de contenidos\n",
    "\n",
    "* [1- Importación de librerias y carga de datos](#chapter1)\n",
    "\n",
    "    \n",
    "* [2 - Preparación de los datos](#chapter2)\n",
    "\n",
    "    * [2 - 1 Preparación de datos para el modelo de regresion logística](#section_2_1)\n",
    "    * [2 - 2 Preparación de datos para el modelo de arbol de desición y bosque aleatorio](#section_2_2) \n",
    "  \n",
    "    \n",
    "* [3- Entrenamiento y calculo de F1](#chapter3)\n",
    "\n",
    "    * [3 - 1 Regresión Logística](#section_3_1)\n",
    "    * [3 - 2 Arbol de desición](#section_3_2) \n",
    "    * [3 - 3 Bosque aleatorio](#section_3_3) \n",
    "  \n",
    "  \n",
    "* [4- Equilibrio de clases](#chapter4)\n",
    "\n",
    "    * [4 - 1 Regresión Logística - con clases equilibradas](#section43_1)\n",
    "    * [4 - 2 Arbol de desición- con clases equilibradas](#section_4_2) \n",
    "    * [4 - 3 Bosque aleatorio- con clases equilibradas](#section_4_3) \n",
    "\n",
    "\n",
    "* [5- Comprobación del modelo](#chapter5)\n",
    "\n",
    "\n",
    "* [6- Evaluación de ajuste del umbral](#chapter6)\n",
    "\n",
    "\n",
    "* [7- Conclusiones](#chapter7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de librerias y análisis de datos <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importacion de librerias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rownumber</th>\n",
       "      <th>customerid</th>\n",
       "      <th>surname</th>\n",
       "      <th>creditscore</th>\n",
       "      <th>geography</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rownumber  customerid   surname  creditscore geography  gender  age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   tenure    balance  numofproducts  hascrcard  isactivemember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   estimatedsalary  exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns = data.columns.str.lower()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mediana 5.0\n",
      "media 4.997690023099769\n"
     ]
    }
   ],
   "source": [
    "## Se rellenan valores usentes de Tenure. Se evaluan la media y la mediana\n",
    "tenure_median = data['tenure'].median()\n",
    "tenure_mean = data['tenure'].mean()\n",
    "print(\"mediana\", tenure_median)\n",
    "print(\"media\", tenure_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no hay valores atipicos en datos de TENURE, se rellenan condicionados a la variable BALANCE\n",
    "\n",
    "tenure_mean = data.groupby(['age'])['tenure'].transform('median')\n",
    "\n",
    "data['tenure'] = data['tenure'].fillna(tenure_mean)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   rownumber        10000 non-null  int64  \n",
      " 1   customerid       10000 non-null  int64  \n",
      " 2   surname          10000 non-null  object \n",
      " 3   creditscore      10000 non-null  int64  \n",
      " 4   geography        10000 non-null  object \n",
      " 5   gender           10000 non-null  object \n",
      " 6   age              10000 non-null  int64  \n",
      " 7   tenure           10000 non-null  float64\n",
      " 8   balance          10000 non-null  float64\n",
      " 9   numofproducts    10000 non-null  int64  \n",
      " 10  hascrcard        10000 non-null  int64  \n",
      " 11  isactivemember   10000 non-null  int64  \n",
      " 12  estimatedsalary  10000 non-null  float64\n",
      " 13  exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# se verifica el tratamiento de ausentes\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se verifica eliminación de ausentes\n",
    "data['tenure'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se verifica presencia de datos duplicados\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los datos y creación de conjuntos de entrenamiento, validacion y test <a class=\"anchor\" id=\"chapter2\"></a>\n",
    "\n",
    "- Se utilizarán modelos de clasificación dado que el objetivo es categeorico. \n",
    "- Para la transformacieon de las características categóricas, utilizaremos One Hot Encoder para el modelo de Regresión logística y Ordinal encoder para los modelos de Arbol de Decisión y bosque aleatorio\n",
    "- En el caso del modelo de regresión logística, tambien se realizará un escalado de variables numéricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de datos para el modelo de regresión logística <a class=\"anchor\" id=\"section_2_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rownumber</th>\n",
       "      <th>customerid</th>\n",
       "      <th>surname</th>\n",
       "      <th>creditscore</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "      <th>geography_France</th>\n",
       "      <th>geography_Germany</th>\n",
       "      <th>geography_Spain</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rownumber  customerid   surname  creditscore  age  tenure    balance  \\\n",
       "0          1    15634602  Hargrave          619   42     2.0       0.00   \n",
       "1          2    15647311      Hill          608   41     1.0   83807.86   \n",
       "2          3    15619304      Onio          502   42     8.0  159660.80   \n",
       "3          4    15701354      Boni          699   39     1.0       0.00   \n",
       "4          5    15737888  Mitchell          850   43     2.0  125510.82   \n",
       "\n",
       "   numofproducts  hascrcard  isactivemember  estimatedsalary  exited  \\\n",
       "0              1          1               1        101348.88       1   \n",
       "1              1          0               1        112542.58       0   \n",
       "2              3          1               0        113931.57       1   \n",
       "3              2          0               0         93826.63       0   \n",
       "4              1          1               1         79084.10       0   \n",
       "\n",
       "   geography_France  geography_Germany  geography_Spain  gender_Female  \\\n",
       "0                 1                  0                0              1   \n",
       "1                 0                  0                1              1   \n",
       "2                 1                  0                0              1   \n",
       "3                 1                  0                0              1   \n",
       "4                 0                  0                1              1   \n",
       "\n",
       "   gender_Male  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se aplica OHE a las columnas Geography y Gender\n",
    "data_ohe = pd.get_dummies(data, drop_first = False, columns = ['geography', 'gender'])\n",
    "data_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Se separan las caracteristicas del objetivo. A su vez, se elimina del analisis la columna 'Surname'\n",
    "\n",
    "target_ohe = data_ohe['exited']\n",
    "features_ohe = data_ohe.drop(['exited', 'surname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se segmentan los datos en tres conjuntos (entrenamiento (60%), validacion (20%)y prueba (20%)). El tipo de plan es la variable objetivo\n",
    "\n",
    "\n",
    "features_ohe_train, features_ohe_valid, target_ohe_train, target_ohe_valid = train_test_split(features_ohe, target_ohe, test_size = 0.4, random_state= 12345)\n",
    "features_ohe_test, features_ohe_valid, target_ohe_test, target_ohe_valid  = train_test_split(features_ohe_valid, target_ohe_valid, test_size = 0.5, random_state= 12345)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_136/2433751039.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_ohe_train[numeric] = scaler.transform(features_ohe_train[numeric])\n",
      "/opt/conda/lib/python3.9/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    }
   ],
   "source": [
    "# Se escalan las caracteristicas numericas (por ser un modelo basado en regresion)\n",
    "\n",
    "numeric = ['creditscore','age', 'tenure', 'balance', 'numofproducts', 'estimatedsalary']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_ohe_train[numeric])\n",
    "features_ohe_train[numeric] = scaler.transform(features_ohe_train[numeric])\n",
    "features_ohe_valid[numeric] = scaler.transform(features_ohe_valid[numeric])\n",
    "features_ohe_test[numeric] = scaler.transform(features_ohe_test[numeric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de datos para el modelo de árbol de desición y bosque aleatorio  <a class=\"anchor\" id=\"section_2_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rownumber</th>\n",
       "      <th>customerid</th>\n",
       "      <th>surname</th>\n",
       "      <th>creditscore</th>\n",
       "      <th>geography</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2736.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5068.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3258.0</td>\n",
       "      <td>1177.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5639.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2104.0</td>\n",
       "      <td>2040.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5793.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5707.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5435.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4704.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6899.0</td>\n",
       "      <td>1822.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3696.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3925.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995.0</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4827.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>1336.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5087.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997.0</td>\n",
       "      <td>717.0</td>\n",
       "      <td>1570.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2062.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998.0</td>\n",
       "      <td>4656.0</td>\n",
       "      <td>2345.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4639.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999.0</td>\n",
       "      <td>2497.0</td>\n",
       "      <td>2751.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rownumber  customerid  surname  creditscore  geography  gender   age  \\\n",
       "0           0.0      2736.0   1115.0        228.0        0.0     0.0  24.0   \n",
       "1           1.0      3258.0   1177.0        217.0        2.0     0.0  23.0   \n",
       "2           2.0      2104.0   2040.0        111.0        0.0     0.0  24.0   \n",
       "3           3.0      5435.0    289.0        308.0        0.0     0.0  21.0   \n",
       "4           4.0      6899.0   1822.0        459.0        2.0     0.0  25.0   \n",
       "...         ...         ...      ...          ...        ...     ...   ...   \n",
       "9995     9995.0      1599.0   1999.0        380.0        0.0     1.0  21.0   \n",
       "9996     9996.0       161.0   1336.0        125.0        0.0     1.0  17.0   \n",
       "9997     9997.0       717.0   1570.0        318.0        0.0     0.0  18.0   \n",
       "9998     9998.0      4656.0   2345.0        381.0        1.0     1.0  24.0   \n",
       "9999     9999.0      2497.0   2751.0        401.0        0.0     0.0  10.0   \n",
       "\n",
       "      tenure  balance  numofproducts  hascrcard  isactivemember  \\\n",
       "0        2.0      0.0            0.0        1.0             1.0   \n",
       "1        1.0    743.0            0.0        0.0             1.0   \n",
       "2       10.0   5793.0            2.0        1.0             0.0   \n",
       "3        1.0      0.0            1.0        0.0             0.0   \n",
       "4        2.0   3696.0            0.0        1.0             1.0   \n",
       "...      ...      ...            ...        ...             ...   \n",
       "9995     6.0      0.0            1.0        1.0             0.0   \n",
       "9996    12.0    124.0            0.0        1.0             1.0   \n",
       "9997     9.0      0.0            0.0        0.0             1.0   \n",
       "9998     3.0    427.0            1.0        1.0             0.0   \n",
       "9999     6.0   4112.0            0.0        1.0             0.0   \n",
       "\n",
       "      estimatedsalary  exited  \n",
       "0              5068.0     1.0  \n",
       "1              5639.0     0.0  \n",
       "2              5707.0     1.0  \n",
       "3              4704.0     0.0  \n",
       "4              3925.0     0.0  \n",
       "...               ...     ...  \n",
       "9995           4827.0     0.0  \n",
       "9996           5087.0     0.0  \n",
       "9997           2062.0     1.0  \n",
       "9998           4639.0     1.0  \n",
       "9999           1878.0     0.0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se utiiza  OrdinalEncoder para transformar variables categoricas\n",
    "\n",
    "encoder =  OrdinalEncoder()\n",
    "data_ordinal = pd.DataFrame(encoder.fit_transform(data), columns = data.columns)\n",
    "data_ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se segmentan los datos en tres conjuntos (entrenamiento (60%), validacion (20%)y prueba (20%)). El tipo de plan es la variable objetivo\n",
    "features_ord = data_ordinal.drop('exited', axis=1)\n",
    "target_ord = data_ordinal['exited']\n",
    "features_ord_train, features_ord_valid, target_ord_train, target_ord_valid = train_test_split(features_ord, target_ord, test_size = 0.4, random_state= 12345)\n",
    "features_ord_test, features_ord_valid, target_ord_test, target_ord_valid  = train_test_split(features_ord_valid, target_ord_valid, test_size = 0.5, random_state= 12345)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y calculo de F1_score  <a class=\"anchor\" id=\"chapter3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Regresión logística  <a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamiento y cálculo de F1 score para el modelo de regresión logística\n",
    "\n",
    "model_log = LogisticRegression(random_state=54321, solver='liblinear')  # se inicializa el constructor de regresión logística con los parámetros random_state=54321 y solver='liblinear'\n",
    "model_log.fit(features_ohe_train, target_ohe_train) # se entrena el modelo en el conjunto de entrenamiento\n",
    "predictions_log = model_log.predict(features_ohe_valid) # se predicen valores \n",
    "f1_score_log = f1_score(target_ohe_valid, predictions_log) # se calcula F1 score en el conjunto de validación\n",
    "\n",
    "print(\"F1 score del modelo de regresión logística en el conjunto de validación:\", f1_score_log)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de árbol de desición  <a class=\"anchor\" id=\"section_3_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamiento y seleccion del mejor modelo de Arbol de decisión\n",
    "\n",
    "best_model_decision_tree = None\n",
    "best_result_decision_tree = 0\n",
    "best_depth_decision_tree  = 0\n",
    "for depth in range(1, 12):\n",
    "    model_tree = DecisionTreeClassifier(random_state=12345, max_depth= depth) #se crea el modelo con la profundidad depth\n",
    "    model_tree.fit(features_ord_train, target_ord_train) # se entrena el modelo \n",
    "    predictions_tree = model_tree.predict(features_ord_valid) # se obtienen las predicciones del modelo\n",
    "    f1_score_tree = f1_score(target_ord_valid, predictions_tree) # se calcula F1 score\n",
    "    if f1_score_tree > best_result_decision_tree:\n",
    "        best_model_decision_tree = model_tree # guarda el modelo que corresponde a la mejor puntuacion de F1 score\n",
    "        best_result_decision_tree = f1_score_tree # guarda la mejor puntuacion de F1 score\n",
    "        best_depth_decision_tree = depth # guarda la profundidad que corresponde a la mejor puntuacion de F1 score\n",
    "\n",
    "print(\"Mejor modelo 'Arbol de decision':\")\n",
    "print(\"F1_score:\", best_result_decision_tree, \"\", \"Profundidad:\",  best_depth_decision_tree )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de bosque aleatorio  <a class=\"anchor\" id=\"section_3_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamiento y seleccion del mejor modelo de bosque aleatorio\n",
    "\n",
    "best_score_random_forest = 0\n",
    "best_est_random_forest = 0\n",
    "best_depth_random_forest = 0\n",
    "for est in range(1, 14): # selecciona el rango del hiperparámetro\n",
    "    for depth in range(1,12):\n",
    "        model_forest = RandomForestClassifier(random_state=54321, max_depth= depth, n_estimators=est) # configura el número de árboles\n",
    "        model_forest.fit(features_ord_train, target_ord_train) # entrena el modelo en el conjunto de entrenamiento\n",
    "        predictions_forest = model_forest.predict(features_ord_valid)\n",
    "        f1_score_forest = f1_score(target_ord_valid, predictions_forest) # calcula la puntuación de f1 en el conjunto de validación\n",
    "        if f1_score_forest > best_score_random_forest:\n",
    "            best_model_forest = model_forest\n",
    "            best_score_random_forest = f1_score_forest# guarda la mejor puntuación de F1 en el conjunto de validación\n",
    "            best_est_random_forest = est# guarda el número de estimadores que corresponden a la mejor puntuación de F1\n",
    "            best_depth_random_forest = depth # guarda la la profundidad que corresponde a la mejor puntacion den F1\n",
    "\n",
    "print(\"Mejor modelo 'Bosque Aleatorio':\")\n",
    "print(\"F1_score:\", best_score_random_forest, \"\", \"Profundidad:\",  best_depth_random_forest, \"n_estimators:\", best_est_random_forest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Los valores de F1 score no  superan el minimo de 0.59 solicitado en ninguno de los 3 modelos. Se analiza el equilibrio de clases para evaluar una mejora en los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Equilibrio de clases <a class=\"anchor\" id=\"chapter4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evauluación del  equilibrio de clases\n",
    "exited_frequency = data['exited'].value_counts(normalize=True)\n",
    "exited_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se observa un fuerte desequilibrio de clases, por lo que se procede a balancerla y entrenar los modelos con la clase balanceada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea una funcion para SOBREMUESTRO\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_upsampled, target_upsampled\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo regresión logística - con clases equilibradas  <a class=\"anchor\" id=\"section_4_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se aplica la funcion de sobremuestreo al modelo de entrenamiento (creado para regresion logistica) y calcula el F1 score del modelo de regresion logistica con clase equilibrada\n",
    "features_ohe_upsampled, target_ohe_upsampled = upsample(\n",
    "    features_ohe_train, target_ohe_train, 10\n",
    ")\n",
    "\n",
    "model_log = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model_log.fit(features_ohe_upsampled, target_ohe_upsampled)#entrenamiento del modelo\n",
    "predicted_log = model_log.predict(features_ohe_valid)\n",
    "F1_score_log =  f1_score(target_ohe_valid, predicted_log)\n",
    "print('F1 score del modelo de regresión logística con clases equilibradas por sobremuestreo:',F1_score_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equilibrio de clases con hiperparametro classweight = balanced\n",
    "\n",
    "model_log = LogisticRegression(random_state=12345, solver='liblinear', class_weight = 'balanced')\n",
    "model_log.fit(features_ohe_train, target_ohe_train) #entrenamiento del modelo\n",
    "predicted_log = model_log.predict(features_ohe_valid)\n",
    "F1_score_log = f1_score(target_ohe_valid, predicted_log)\n",
    "print('F1 score del modelo de regresion logistica con clases equilibradas con classweight:', F1_score_log)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Se logro una mejora con el balanceo de clases en el modelo de regresion logistica pero aun está por debajo del mínimo requerido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Arbol de desición - con clases equilibradas  <a class=\"anchor\" id=\"section_4_2\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se aplica la funcion de sobremuestreo al modelo de entrenamiento (creado para arboles) y calcula el F1 score del modelo de arbol de desicion con clase equilibrada\n",
    "features_ord_upsampled, target_ord_upsampled = upsample(\n",
    "    features_ord_train, target_ord_train, 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se busca el mejor modelo de árbol de desición con clases equilibradas por sobremuestro\n",
    "\n",
    "best_model_decision_tree = None\n",
    "best_result_decision_tree = 0\n",
    "best_depth_decision_tree  = 0\n",
    "for depth in range(1, 12):\n",
    "    model_tree = DecisionTreeClassifier(random_state=12345, max_depth= depth) #se crea el modelo con la profundidad depth\n",
    "    model_tree.fit(features_ord_upsampled, target_ord_upsampled) # se entrena el modelo \n",
    "    predictions_tree = model_tree.predict(features_ord_valid) # se obtienen las predicciones del modelo\n",
    "    f1_score_tree = f1_score(target_ord_valid, predictions_tree) # se calcula F1\n",
    "    if f1_score_tree > best_result_decision_tree:\n",
    "        best_model_decision_tree = model_tree # guarda el modelo que corresponde a la mejor puntuacion de F1\n",
    "        best_result_decision_tree = f1_score_tree # guarda la mejor puntuacion de accuracy\n",
    "        best_depth_decision_tree = depth # guarda la profundidad que corresponde a la mejor puntuacion de F1\n",
    "\n",
    "print(\"Mejor modelo 'Arbol de decision con clases equilibradas por sobremuestreo':\")\n",
    "print(\"F1_score:\", best_result_decision_tree, \"\", \"Profundidad:\",  best_depth_decision_tree )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se busca el mejor modelo de árbol de desición con clases equilibradas con asignacion de class_weight\n",
    "\n",
    "best_model_decision_tree = None\n",
    "best_result_decision_tree = 0\n",
    "best_depth_decision_tree  = 0\n",
    "for depth in range(1, 12):\n",
    "    model_tree = DecisionTreeClassifier(random_state=12345, max_depth= depth, class_weight = 'balanced') #se crea el modelo con la profundidad depth\n",
    "    model_tree.fit(features_ord_train, target_ord_train) # se entrena el modelo \n",
    "    predictions_tree = model_tree.predict(features_ord_valid) # se obtienen las predicciones del modelo\n",
    "    f1_score_tree = f1_score(target_ord_valid, predictions_tree) # se calcula la f1\n",
    "    if f1_score_tree > best_result_decision_tree:\n",
    "        best_model_decision_tree = model_tree # guarda el modelo que corresponde a la mejor puntuacion de f1\n",
    "        best_result_decision_tree = f1_score_tree # guarda la mejor puntuacion de f1\n",
    "        best_depth_decision_tree = depth # guarda la profundidad que corresponde a la mejor puntuacion de f1\n",
    "\n",
    "print(\"Mejor modelo 'Arbol de decisión con clases equilibradas por sobremuestreo':\")\n",
    "print(\"F1_score:\", best_result_decision_tree, \"\", \"Profundidad:\",  best_depth_decision_tree )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - La mejora del modelo de arbol de decisión lograda con el equilibrio de clases es leve y aún no supera el mínimo de 0,59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de bosque aleatorio - con clases equilibradas  <a class=\"anchor\" id=\"section_4_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se busca el mejor bosque aleatorio con clases equilibradas por sobremuestro\n",
    "\n",
    "best_score_random_forest = 0\n",
    "best_est_random_forest = 0\n",
    "best_depth_random_forest = 0\n",
    "for est in range(1, 14): # selecciona el rango del hiperparámetro\n",
    "    for depth in range(1,12):\n",
    "        model_forest = RandomForestClassifier(random_state=54321, max_depth= depth, n_estimators=est) # configura el número de árboles\n",
    "        model_forest.fit(features_ord_upsampled, target_ord_upsampled) # entrena el modelo en el conjunto de entrenamiento\n",
    "        predictions_forest = model_forest.predict(features_ord_valid)\n",
    "        f1_score_forest = f1_score(target_ord_valid, predictions_forest) # calcula la puntuación de f1 en el conjunto de validación\n",
    "        if f1_score_forest > best_score_random_forest:\n",
    "            best_score_random_forest = f1_score_forest# guarda la mejor puntuación de f1 en el conjunto de validación\n",
    "            best_est_random_forest = est# guarda el número de estimadores que corresponden a la mejor puntuación de f1\n",
    "            best_depth_random_forest = depth # guarda la la profundidad que corresponde a la mejor puntacion den f1\n",
    "\n",
    "print(\"Mejor modelo 'Bosque Aleatorio con clases equilibradas por sobremuestreo':\")\n",
    "print(\"F1_score:\", best_score_random_forest, \"\", \"Profundidad:\",  best_depth_random_forest, \"n_estimators:\", best_est_random_forest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se busca el mejor bosque aleatorio con clases equilibradas por ajuste de class_weight\n",
    "\n",
    "best_score_random_forest = 0\n",
    "best_est_random_forest = 0\n",
    "best_depth_random_forest = 0\n",
    "for est in range(1, 20): # selecciona el rango del hiperparámetro\n",
    "    for depth in range(1,14):\n",
    "        model_forest = RandomForestClassifier(random_state=54321, max_depth= depth, n_estimators=est, class_weight = 'balanced') # configura el número de árboles\n",
    "        model_forest.fit(features_ord_train, target_ord_train) # entrena el modelo en el conjunto de entrenamiento\n",
    "        predictions_forest = model_forest.predict(features_ord_valid)\n",
    "        f1_score_forest = f1_score(target_ord_valid, predictions_forest) # calcula la puntuación de f1 en el conjunto de validación\n",
    "        if f1_score_forest > best_score_random_forest:\n",
    "            best_score_random_forest = f1_score_forest# guarda la mejor puntuación de f1 en el conjunto de validación\n",
    "            best_est_random_forest = est# guarda el número de estimadores que corresponden a la mejor puntuación de f1\n",
    "            best_depth_random_forest = depth # guarda la la profundidad que corresponde a la mejor puntacion den f1\n",
    "\n",
    "print(\"Mejor modelo 'Bosque Aleatorio con clases equilibradas por Classweight':\")\n",
    "print(\"F1_score:\", best_score_random_forest, \"\", \"Profundidad:\",  best_depth_random_forest, \"n_estimators:\", best_est_random_forest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### - El modelo de bosque aleatorio es el que tuvo mayor mejora con el equilibrio de clase alcanzando un valore de 0.6, para una cantidad de 16 arboles y una profundidad de 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprobación de la calidad del modelo <a class=\"anchor\" id=\"chapter5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calidad del modelo en el conjunto de prueba con los hiperparametros del mejor modelo de bosque aleatorio seleccionado\n",
    "\n",
    "best_model_forest = RandomForestClassifier(random_state=54321, max_depth= 8, n_estimators= 16, class_weight = 'balanced') # configura el número de árboles\n",
    "best_model_forest.fit(features_ord_train, target_ord_train) # entrena el modelo en el conjunto de entrenamiento\n",
    "predictions_best_forest = best_model_forest.predict(features_ord_test)\n",
    "\n",
    "f1_score_test = f1_score(target_ord_test, predictions_best_forest) \n",
    "        \n",
    "print(\"F1_score del testo de validacion\", f1_score_test)     \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- EL f1 score de los datos de prueba da muy similar al del conjunto de validacion por lo que se comprueba la calidad del modelo seleccionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## se realiza una prueba de cordura: se compara el F1 score del modelo seleccionado con el de un modelo aleatorio\n",
    "\n",
    "predictions_random = pd.Series(np.random.choice([0, 1], size=len(target_ord_test)), index=target_ord_test.index)\n",
    "\n",
    "f1_score_random = f1_score(target_ord_test, predictions_random)\n",
    "print(\"F1 score de prueba de cordura:\", f1_score_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- EL f1 score obtenido con el modelo aleatorio es mucho menos en comparación con el obtenido por el modelo en  el del conjunto de validacion por lo que se comprueba la calidad del modelo seleccionado, habiendo pasado la prueba de cordura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculo de roc - auc\n",
    "\n",
    "probabilities_valid = best_model_forest.predict_proba(features_ord_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_ord_valid, probabilities_one_valid)\n",
    "\n",
    "print(auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El valor de la auc - roc es muy elevado respecto del F1 score, podria deberse al desequilibrio de clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalución de ajuste de umbral  <a class=\"anchor\" id=\"chapter6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se evalua la posibilidad de ajustar el umbral dado que se trata de un objetivo de clases desequilibradas\n",
    "\n",
    "probabilities_valid = best_model_forest.predict_proba(features_ord_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "   \n",
    "for threshold in np.arange(0.4, 0.7, 0.02):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    f1_score_forest = f1_score(target_ord_valid, predicted_valid)\n",
    "    print(\n",
    "        'Threshold = {:.2f} | F1_score = {:.3f}'.format(\n",
    "            threshold, f1_score_forest))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_f1_score_forest = 0\n",
    "for threshold in np.arange(0.4, 0.7, 0.02):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    f1_score_forest = f1_score(target_ord_valid, predicted_valid)\n",
    "    if f1_score_forest > best_f1_score_forest:\n",
    "        best_f1_score_forest = f1_score_forest\n",
    "        best_threhold_forest = threshold\n",
    "        best_predicted = predicted_valid\n",
    "print('threshold_best_f1:', best_threhold_forest, 'F1 score', best_f1_score_forest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- EL mejor valor de F1 score se obtiene con umbral 0.5 (el msimo que por defecto), por lo que no se modifica el umbral para las predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones <a class=\"anchor\" id=\"chapter7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Los datos proporcionados contaban con valores ausentes en los datos de Ternure, los cuales fueron completados con la media de dichos valores\n",
    " - Dado que se trata de un objetivo de tipo catogorico, se utilizaron modelos de clasificacion para resolver el caso\n",
    " - Se transformaron las caracteristicas categoricas utilizando ordinal encoder para el caso de los modelos de arboles (arbol de desición y bosque aleatorio) y utilizando one hot encoder para el caso de modelo de regresion lineal\n",
    " - Las caracteristicas numericas se escalaron para el entrenamiento del modelo de regresion lineal (ya que no es necesario hacerlo para los modelos de arboles)\n",
    " - Se calcularon los valores de F1 score para los tres modelos, optimizando los hiperparametros de profundidad y cantidad de estimadores donde correspondia. En ninguno de los tres casos se supero el valor minimo requerido de F1 score de 0,58\n",
    " - Se procedio a equilibrar las clases del objetivo con dos metodos: ajuste del hiperparametro \"class_weight\" y mediante sobremuestero\n",
    " - Se calcularon para los tres modelos, utilizando ambos metodos de equilibrio de clases, los nuevos valores de F1 score:\n",
    "     - En el modelo de regresion logistica , si bien se obtuvo una gran mejora del parametro , el valor aun quedo muy por debajo de minimo requerido\n",
    "     - En el modelo de arbol de desicion, la mejora fue muy sutil, y no se alcanzo el minimo requerido\n",
    "     - El valor de F1 alcanzado en el modelo de bosque aleatorio fue el unico que logro superar el minimo de f1 requerido, alcanzando un valor de 0.6, por lo cual , resulto ser el modelo seleccionado \n",
    "     \n",
    "- Se ralizo una prueba de cordura, comparando el valor de F1 de un modelo aleatorio con el modelo seleccionado, siendo  el f1 score obtenido con el modelo aleatorio es mucho menor en comparación con el obtenido por el modelo en  el del conjunto de validacion por lo que se comprueba la calidad del modelo seleccionado, habiendo pasado la prueba de cordura\n",
    "- Se realizo una comprobacion de la calidad del modelo, mediando el calculo de f1 en el conjunto de testeo, obteniendo un valor muy similar al obtenido ocn los datos de validacion lo que comprueba la calidad del modelo\n",
    "- Se calculo el valor se auc  - roc, el cual resulto ser 0.84, un valor muy superior al del f1_score, por el desequilibrio de clases\n",
    "- Se evaluo la convenciencia de ajustar el umbral, descartandose dicha posibilidad dado que el mayor valor de F1_score se da en el umbral por defecto del 0,5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
